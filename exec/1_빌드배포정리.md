# 1. 빌드 배포 정리

## 목차

1. [기술 스택](#기술-스택)
2. [빌드 및 배포](#빌드-및-배포)


## 기술 스택

1. 이슈 관리 : Jira
2. 형상 관리 : Gitlab
3. 빌드/배포 관리 : Jenkins `2.455`
4. 커뮤니케이션 : MatterMost, Notion, Discord
5. 개발 환경
    1) 운영체제 Window10
    2) IDE
        - VSCode `1.85.1`
        - IntelliJ `2023.3.2`
    3) 데이터베이스 : MySQL `8.4.0`
    4) 서버 : AWS EC2
        - Ubuntu `20.04 LTS`
        - Docker `26.1.0`
        - Kubernetes `1.30`
        - Helm `3.14.2`
        - Traefik `2.11.1`(Helm Chart traefik-27.0.2)
        - Https/SSL `Let's Encrypt`
6. 세부사항
    1) Frontend
        - lang: HTML5, CSS3, Typescript, Node.js `16.16.0`
        - Framework:
            * React: `18.2.0`
        - 주요 Libraries
            * axios: `1.6.8`
            * zustand `4.5.2`
        - 개발 도구
            * ESLint: `8.57.0`

    2) Backend
        - Language: Java 17, Java 21(HR, Payment, Restaurant)
        - Framework:
            *  Spring Boot: `3.2.5`
            *  Spring Security
            *  Spring Data JPA
        - 주요 Libraries:
            * Lombok
            * QueryDSL
            * OpenFeign
            * Jjwt : `0.12.5`
            * unirest: `1.4.9`
        -  개발 도구:
            *  Spring Boot Devtools
            *  Gradle `8.7`
        -  API 문서화:
            *  Swagger

    3) Backend(Fastapi)
        - Language : Python 3.9.7
        - Framework :
            * FastAPI : `0.111.0`
        - 주요 Libraries:
            * numpy : `1.26.4`
            * dlib : `19.24.2`
            * pytorch `2.3.0`
            * face-recognition : `1.3.0`

    

## 빌드 및 배포


### 1. AWS EC2 기본 설정 및 nginx 설치
1) (선택) 우분투 미러서버 변경
    - 처음 우분투를 받았을 때 기본설정 되어 있는 미러서버는 느리거나 update시 일부 다운로드가 되지 않는 오류가 발생하는 경우가 있음
    - 국내에서 접근 가능한 가장 빠른 카카오 미러서버로 기본설정 변경

    ```bash
    $ sudo vim /etc/apt/sources.list

    # esc버튼 클릭 후
    :%s/{기존에 입력되어 있던 미러서버 주소}/mirror.kakao.com
    :wq

    deb http://mirror.kakao.com/ubuntu/ focal main restricted

    deb http://mirror.kakao.com/ubuntu/ focal-updates main restricted

    deb http://mirror.kakao.com/ubuntu/ focal-updates universe

    deb http://mirror.kakao.com/ubuntu/ focal multiverse

    deb http://mirror.kakao.com/ubuntu/ focal-updates multiverse

    deb http://mirror.kakao.com/ubuntu/ focal-backports main restricted universe multiverse
    ```

2) 쿠버네티스 클러스터 설치
    ```bash
    # Docker 및 containerd 패키지 업데이트하고, Docker repository를 APT에 추가
    $ sudo apt-get update
    $ sudo apt-get install apt-transport-https ca-certificates curl software-properties-common containerd
    $ curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -
    $ sudo add-apt-repository "deb [arch=amd64] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable"
    
    # Docker CE 및 containerd를 설치
    $ sudo apt-get update
    $ sudo apt-get install docker-ce containerd
    
    # SWAP을 OFF하고 containerd 설정을 마스터 노드와 워커 노드 모두에서 실행
    $ sudo swapoff -a
    $ sudo sed -i -e 's/GRUB_CMDLINE_LINUX_DEFAULT="[^"]*/& swapaccount=1/' /etc/default/grub
    $ sudo update-grub
    $ sudo systemctl restart containerd
    $ sudo mkdir -p /etc/containerd
    $ containerd config default | sudo tee /etc/containerd/config.toml
    $ sudo sed -i -e "s/^\\(\\[plugins.\"io.containerd.grpc.v1.cri\".containerd.runtimes.runc.options\\]\\)/\1\n  SystemdCgroup = true/" /etc/containerd/config.toml
    $ sudo systemctl restart containerd
   ```
    - 쿠버네티스 패키지 설치하고 네트워크 환경을 설정
    ```bash
    # Google Cloud의 패키지 서명 키를 추가하고 쿠버네티스 패키지를 APT에 추가
    $ curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add -
    $ echo "deb http://apt.kubernetes.io/ kubernetes-xenial main" | sudo tee /etc/apt/sources.list.d/kubernetes.list
    
    # 쿠버네티스 패키지 설치
    $ sudo apt-get update
    $ sudo apt-get install -y kubelet kubeadm kubectl
    
    # 메모리 내 IP 테이블을 활성화하여 트래픽을 능동적으로 Forword
    $ echo net.bridge.bridge-nf-call-iptables=1 | sudo tee -a /etc/sysctl.conf
    $ echo net.ipv4.ip_forward=1 | sudo tee -a /etc/sysctl.conf
    $ echo net.bridge.bridge-nf-call-ip6tables=1 | sudo tee -a /etc/sysctl.conf
    $ sudo sysctl -p
    ```
   
    - Kubeadm을 사용하여 클러스터 설정 
    ```bash
    # 마스터 노드에서
    $ sudo kubeadm init --pod-network-cidr=192.168.0.0/16
    
    # 워커 노드에서 (위에서 출력된 join 명령을 실행)
    $ sudo kubeadm join --token {token} {master-ip}:{master-port} --discovery-token-ca-cert-hash {hash}
    ```
    - 네트워크 플러그인으로 Calico를 사용
    ```bash
    # 마스터 노드에서
    $ kubectl apply -f https://docs.projectcalico.org/v3.14/manifests/calico.yaml
    ```

    - 쿠버네티스 클러스터 설정은 버전, 환경에 따라 다를 수 있으므로 가급적 [Kubernetes 공식 문서](https://kubernetes.io/docs/home/)와 [Calico 공식 문서](https://docs.tigera.io/calico/latest/getting-started/kubernetes/quickstart)을 참고하여 충분한 배경지식과 CLI 명령어 등을 숙지하여 진행.
   

3) 백엔드 빌드
    * BackEnd Dockerfile
    ```dockerfile
    # Build stage
    FROM gradle:8.7.0-jdk17-alpine AS build
    COPY --chown=gradle:gradle . /home/gradle/src
    WORKDIR /home/gradle/src
    RUN gradle bootJar --no-daemon
    
    # Package stage
    FROM openjdk:17-jdk-alpine
    ENV SPRING_PROFILES_ACTIVE=local
    COPY --from=build /home/gradle/src/build/libs/*.jar /app/app.jar
    EXPOSE 8080
    ENTRYPOINT ["java","-Dspring.profiles.active=local","-jar","/app/app.jar"]
    ```

    * 각 서비스 별 Docker Image 빌드 후 Docker Hub push
    ```bash
    # Docker에 로그인
    docker login -u {docker-username} -p {docker-password}
    
    # Docker 이미지 빌드
    docker build -t {docker-username}/{backend-service-name}:{tag} .
    docker push {docker-username}/{backend-service-name}:{tag}

    ```

    * ❗ application-local.yaml 파일은 git에 업로드되지 않으므로 따로 설정해줌
    ```yaml
   # application-local.yaml(approval)
    spring:
        datasource:
            url: jdbc:mysql://{{mysql-host}}:{{mysql-port}}/payment?characterEncoding=UTF-8&serverTimezone=Asia/Seoul
            username: {{mysql-username}}
            password: {{mysql-password}}
            driver-class-name: com.mysql.cj.jdbc.Driver
        redis:
            host: {{redis-host}}
            password: {{redis-password}}
            port: {{redis-port}}
        kafka:
            producer:
              bootstrap-servers: {{bootstrap-servers}}
    feign_hr: http://{{feign-host}}/api/v1/hr
    ```

    ```yaml
   # application-local.yaml(cafe)
    spring:
      data:
        mongodb:
          uri: mongodb://{{mongodb-username}}:{{mongodb-password}}@{{mongodb-host}}:{{mongodb-port}}/bbapcafe
    
    feign_hr: http://{{feign-host}}/api/v1/hr
    ```
   
    ```yaml
   # application-local.yaml(face)
    spring:
      datasource:
        url: jdbc:mysql://{{mysql-host}}:{{mysql-port}}/face?characterEncoding=UTF-8&serverTimezone=Asia/Seoul
        username: {{mysql-username}}
        password: {{mysql-password}}
        driver-class-name: com.mysql.cj.jdbc.Driver
    
    feign-fast-api : http://{{feign-host}}/api/v1
    ```
   
    ```yaml
    # application-local.yaml(hr)
    secret-key: {{jwt-secret-key}}
    
    spring:
      datasource:
        url: jdbc:mysql://{{mysql-host}}:{{mysql-port}}/hr?characterEncoding=UTF-8&serverTimezone=Asia/Seoul
        username: {{mysql-username}}
        password: {{mysql-password}}
        driver-class-name: com.mysql.cj.jdbc.Driver
        hikari:
          connection-timeout: 300000
    
      data:
        redis:
          host: {{redis-host}}
          port: {{redis-port}}
          password: {{redis-password}}
        
      kafka:
        bootstrap-servers: {{kafka-cluster-urls}}
        producer:
          key-serializer: org.apache.kafka.common.serialization.StringSerializer
          value-serializer: org.apache.kafka.common.serialization.StringSerializer
          properties:
            security.protocol: SASL_PLAINTEXT
            sasl.mechanism: PLAIN
            sasl.jaas.config: org.apache.kafka.common.security.plain.PlainLoginModule required username="{{kafka-username}}" password="{{kafka-password}}";
    
    feign_notice: http://{{feign-notice-host}}/api/v1/notices
    ```

    ```yaml
   # application-local.yaml(notice)
    spring:
      datasource:
        url: jdbc:mysql://{{mysql-host}}:{{mysql-port}}/notification?characterEncoding=UTF-8&serverTimezone=Asia/Seoul
        username: {{mysql-username}}
        password: {{mysql-password}}
        driver-class-name: com.mysql.cj.jdbc.Driver
    
      data:
        redis:
          host: {{redis-host}}
          password: {{redis-password}}
          port: {{redis-port}}
    
      kafka:
        bootstrap-servers: {{kafka-bootstrap-servers}}
        consumer:
          group-id: notice-service-group
          auto-offset-reset: earliest
          key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
          value-deserializer: org.apache.kafka.common.serialization.StringDeserializer
          properties:
            security.protocol: SASL_PLAINTEXT
            sasl.mechanism: PLAIN
            sasl.jaas.config: org.apache.kafka.common.security.plain.PlainLoginModule required username="{{kafka-username}}" password="{{kafka-password}}";
    ```

    ```yaml
   # application-local.yaml(order)
    spring:
      data:
        mongodb:
          uri: mongodb://{{mongodb-username}}:{{mongodb-password}}@{{mongodb-host}}:{{mongodb-port}}/bbapcafe
        redis:
          host: {{redis-host}}
          password: {{redis-password}}
          port: {{redis-port}}
        kafka:
          producer:
            bootstrap-servers: {{kafka-bootstrap-servers}}
            key-serializer: org.apache.kafka.common.serialization.StringSerializer
            value-serializer: org.apache.kafka.common.serialization.StringSerializer
            properties:
              security.protocol: SASL_PLAINTEXT
              sasl.mechanism: PLAIN
              sasl.jaas.config: org.apache.kafka.common.security.plain.PlainLoginModule required username="{{kafka-username}}" password="{{kafka-password}}";
    
    feign-cafe: http://{{feign-cafe-host}}/api/v1/cafes
    feign-face: http://{{feign-face-host}}/api/v1/faces
    feign-payment: http://{{feign-payment-host}}/api/v1/payments
    feign_hr: http://{{feign-hr-host}}/api/v1/hr
    ```

    ```yaml
   # application-local.yaml(order-room)
    spring:
      redis:
        host: {{redis-host}}
        password: {{redis-password}}
        port: {{redis-port}}
    
      kafka:
        producer:
          bootstrap-servers: {{kafka-bootstrap-servers}}
          key-serializer: org.apache.kafka.common.serialization.StringSerializer
          value-serializer: org.apache.kafka.common.serialization.StringSerializer
          properties:
            security.protocol: SASL_PLAINTEXT
            sasl.mechanism: PLAIN
            sasl.jaas.config: org.apache.kafka.common.security.plain.PlainLoginModule required username="{{kafka-username}}" password="{{kafka-password}}";
        consumer:
          bootstrap-servers: {{kafka-bootstrap-servers}}
          group-id: order_room_group
          auto-offset-reset: earliest
          key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
          value-deserializer: org.apache.kafka.common.serialization.StringDeserializer
          properties:
            security.protocol: SASL_PLAINTEXT
            sasl.mechanism: PLAIN
            sasl.jaas.config: org.apache.kafka.common.security.plain.PlainLoginModule required username="{{kafka-username}}" password="{{kafka-password}}";
    
    feign-order: http://{{feign-order-host}}/api/v1/orders
    feign-hr: http://{{feign-hr-host}}/api/v1/hr
    feign-cafe: http://{{feign-cafe-host}}/api/v1/cafes
    ```
   
    ```yaml
   # application-local.yaml(payment)
    spring:
      datasource:
        url: jdbc:mysql://{{mysql-host}}:{{mysql-port}}/payment?characterEncoding=UTF-8&serverTimezone=Asia/Seoul
        username: {{mysql-username}}
        password: {{mysql-password}}
        driver-class-name: com.mysql.cj.jdbc.Driver
        hikari:
          connection-timeout: 300000
      data:
        redis:
          host: {{redis-host}}
          password: {{redis-password}}
          port: {{redis-port}}
    
      kafka:
        producer:
          bootstrap-servers: {{kafka-bootstrap-servers}}
          key-serializer: org.apache.kafka.common.serialization.StringSerializer
          value-serializer: org.apache.kafka.common.serialization.StringSerializer
          properties:
            security.protocol: SASL_PLAINTEXT
            sasl.mechanism: PLAIN
            sasl.jaas.config: org.apache.kafka.common.security.plain.PlainLoginModule required username="{{kafka-username}}" password="{{kafka-password}}";
    
    feign_restaurant: http://{{feign-restaurant-host}}/api/v1/restaurants
    feign_hr: http://{{feign-hr-host}}/api/v1/hr
    ```
   
    ```yaml
    spring:
      datasource:
        url: jdbc:mysql://{{mysql-host}}:{{mysql-port}}/restaurant?characterEncoding=UTF-8&serverTimezone=Asia/Seoul
        username: {{mysql-username}}
        password: {{mysql-password}}
        driver-class-name: com.mysql.cj.jdbc.Driver
      hikari:
        connection-timeout: 300000
    
      kafka:
        bootstrap-servers: {{kafka-bootstrap-servers}}
        consumer:
          group-id: restaurant-service-group
          auto-offset-reset: earliest
          key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
          value-deserializer: org.apache.kafka.common.serialization.StringDeserializer
          properties:
            security.protocol: SASL_PLAINTEXT
            sasl.mechanism: PLAIN
            sasl.jaas.config: org.apache.kafka.common.security.plain.PlainLoginModule required username="{{kafka-username}}" password="{{kafka-password}}";
    
    feign_hr: http://{{feign-hr-host}}/api/v1/hr
    ```

3) 백엔드 빌드
    * App Dockerfile
    ```dockerfile
    FROM node:lts-alpine3.18 as build-deps
    WORKDIR /app
    COPY package*.json ./
    RUN npm install
    COPY . ./
    RUN npm run build
    
    
    FROM nginx:1.19.0-alpine
    COPY --from=build-deps /app/dist /usr/share/nginx/html
    COPY default.conf /etc/nginx/conf.d/default.conf
    EXPOSE 80
    CMD ["nginx", "-g", "daemon off;"]

    ```
   
    * Kiosk Dockerfile
    ```Dockerfile
    FROM node:lts-alpine3.18 as build-deps
    # Install Python, build tools, pkg-config, and dependencies needed by 'canvas'
    RUN apk update \
        && apk add --no-cache python3 make g++ \
        && apk add --no-cache pkgconfig cairo-dev jpeg-dev pango-dev giflib-dev \
        && ln -sf python3 /usr/bin/python
    
    # Set PYTHON environment variable for node-gyp
    ENV PYTHON=/usr/bin/python3
    
    WORKDIR /app
    COPY package*.json ./
    RUN npm install
    COPY . ./
    RUN npm run build
    
    FROM nginx:1.19.0-alpine
    COPY --from=build-deps /app/dist /usr/share/nginx/html
    COPY default.conf /etc/nginx/conf.d/default.conf
    EXPOSE 80
    CMD ["nginx", "-g", "daemon off;"]
    
    ```

    * 각 서비스 별 Docker Image 빌드 후 Docker Hub push
    ```bash
    # Docker에 로그인
    docker login -u {docker-username} -p {docker-password}
    
    # Docker 이미지 빌드
    docker build -t {docker-username}/{front-service-name}:{tag} .
    docker push {docker-username}/{front-service-name}:{tag}

    ```

    * ❗ .env 파일은 git에 업로드되지 않으므로 따로 설정해줌
    ```
    VITE_FB_API_KEY={{fb-api-key}}
    VITE_FB_AUTH_DOMAIN={{fb-auth-domain}}
    VITE_FB_PROJECT_ID={{fb-project-id}}
    VITE_FB_STORAGE_BUCKET={{fb-storage-bucket}}
    VITE_FB_MESSAGING_SENDER_ID={{fb-messaging-sender-id}}
    VITE_FB_APP_ID={{fb-app-id}}
    VITE_FB_MEASUREMENT_ID={{fb-measurement-id}}
    VITE_VAPID_KEY={{vapid-key}}
    
    VITE_API_URL={{api-url}}
    
    VITE_WEBSOCKET_URL={{websocket-url}}
    ```
